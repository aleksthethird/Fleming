{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fleming Pipeline - ipython notebook version\n",
    "\n",
    "### Note on astrometry.net \n",
    "\n",
    "If the solve keeps timing out and you have `Config.astrometry_timeout` as a large value (or `-1`) then check the timeout in `~/.astropy/config/astroquery.cfg`.\n",
    "\n",
    "\n",
    "#### How to get a key\n",
    "If you do want to upload (eg if machine takes too long solving) you will need a key and add it to `~/.astropy/config/astroquery.cfg` and `pipeline/astrometry_api_key.txt`.\n",
    "The first is a config file (example layout is as below) latter is just a text file containing the key and nothing else.\n",
    "\n",
    "[Go to the website](http://nova.astrometry.net/api_help) and sign in and follow the instructions.\n",
    "\n",
    "Example config:\n",
    "```\n",
    "[astrometry_net]\n",
    "\n",
    "api_key = XXXXX\n",
    "timeout = 1200 ## 20 mins\n",
    "server = http://nova.astrometry.net\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports and setup\n",
    "Run this, change the config cell to suit the field that you want to run for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Imports\n",
    "import pipeline\n",
    "from pipeline import *\n",
    "from pipeline import Pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ME WHEN NOT USING DARK MODE\n",
    "import matplotlib as mpl\n",
    "COLOR = \"white\"\n",
    "#COLOR = \"black\"\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR\n",
    "\n",
    "## A4 paper\n",
    "mpl.rcParams['figure.figsize'] = [11.3, 8.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    raw_image_dir = os.path.expanduser(\"~/mnt/jgt/2022/0301\"),\n",
    "    image_prefix = \"l138_0\",\n",
    "    bias_prefix = \"bias\",\n",
    "    n_sets = 9,\n",
    "    fits_extension = \".fits\",\n",
    "    fits_date_format = \"%Y.%m.%dT%H:%M:%S.%f\",\n",
    "    has_filter_in_header = False,\n",
    "    n_sample_periods = 100,\n",
    "    amplitude_score_threshold = 0.85,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "Run using the general setup from `pipeline/Pipeline.py`.\n",
    "\n",
    "This is as far as you need to run if you want a single field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline.run(config, show_plots=True, show_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline breakdown\n",
    "Below is a rough copy of the `Pipeline.run()` method.\n",
    "\n",
    "Used for picking certain parts to run/rerun.\n",
    "Hopefully minimal kernel restarts are needed when running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = Reducer(config, \"No filter\") ## Only \"No filter\" for Trius\n",
    "\n",
    "r.reduce(skip_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Cataloguer(config)\n",
    "\n",
    "catalogue_image = os.path.join(config.image_dir, config.image_format_str.format(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_sources = c.generate_catalogue(catalogue_image, solve=True)\n",
    "#c.generate_image_times()\n",
    "\n",
    "n_sources = c.generate_catalogue(catalogue_image, solve=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf = ShiftFinder(config, n_sources)\n",
    "\n",
    "sf.generate_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FluxFinder(config, n_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ff.make_light_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DataAnalyser(config, adjusted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std, med, n_positive = da.get_means_and_stds()\n",
    "da.plot_means_and_stds()\n",
    "source_ids = da.get_source_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = VariableDetector(config, source_ids, mean, std, med, n_positive, adjusted=False)\n",
    "exclude_from_avg = vd.std_dev_search(config.avg_exclude_threshold)\n",
    "avg_ids = da.get_ids_for_avg(exclude_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.make_avg_curve(avg_ids)\n",
    "ff.plot_avg_light_curve(config.avg_curve_path, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ff.create_adjusted_light_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DataAnalyser(config, adjusted=True)\n",
    "mean, std, med, n_positive = da.get_means_and_stds()\n",
    "da.plot_means_and_stds()\n",
    "source_ids = da.get_source_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = VariableDetector(config, source_ids, mean, std, med, n_positive, adjusted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variable_ids_s = vd.std_dev_search(config.variability_threshold)\n",
    "variable_ids_a = vd.amplitude_search(config.amplitude_score_threshold)\n",
    "variable_ids = variable_ids_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ff.plot_given_light_curves(variable_ids, adjusted=True, show=True, show_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_table = da.output_results(variable_ids, vd)\n",
    "ff.create_thumbnails(results_table, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Create plots for the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Very much not automated, need to change everything by hand\n",
    "\n",
    "ncols = 4\n",
    "fig, axs = plt.subplots(nrows=3,ncols=ncols, figsize=(16,9))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "\n",
    "for i, (field_id, source_id, n_periods) in enumerate(hand_picked[36:48]):   \n",
    "    config = Config(\n",
    "        image_prefix = field_id,\n",
    "    )\n",
    "    \n",
    "    ## Grab the RA and DEC of the source\n",
    "    cat = Utilities.read_catalogue(config)\n",
    "    idx = np.where(cat['id'] == source_id)[0][0]\n",
    "    ra  = cat['RA'][idx]\n",
    "    dec = cat['DEC'][idx]\n",
    "    if ra > 360 or dec > 180:\n",
    "        continue\n",
    "    ## Grab the adjusted light curve\n",
    "    lc_path = os.path.join(config.adjusted_curve_dir,\n",
    "            config.source_format_str.format(source_id))\n",
    "    lc = np.genfromtxt(lc_path, dtype=config.light_curve_dtype)\n",
    "\n",
    "    ## Plot the light curve\n",
    "    axs[i//ncols,i%ncols].scatter(lc['time']/3600, lc['counts'], marker=\"x\", s=2)\n",
    "\n",
    "    axs[i//ncols,i%ncols].set_xlabel(\"Time [hours]\")\n",
    "    axs[i//ncols,i%ncols].set_ylabel(\"Normalised flux [arb. u.]\")\n",
    "    coord = SkyCoord(ra*u.degree, dec*u.degree)\n",
    "    axs[i//ncols,i%ncols].set_title(\"{}: {}\"\n",
    "                .format(config.source_format_str.format(source_id)[:-4], \n",
    "                        coord.to_string(\"hmsdms\", precision=0)))\n",
    "#fig.delaxes(axs[2,3])\n",
    "#fig.delaxes(axs[2,2])\n",
    "#fig.delaxes(axs[2,1])\n",
    "#fig.delaxes(axs[1,3])\n",
    "#fig.delaxes(axs[1,2])\n",
    "#fig.delaxes(axs[1,1])\n",
    "plt.savefig(\"hand_picked_unsure_4.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug land\n",
    "\n",
    "Use at your own peril.\n",
    "\n",
    "This isn't important to the pipeline, just used to test things.\n",
    "Can be deleted if needed\n",
    "\n",
    "If you change something in the `pipeline/*.py` then you need to reload the modules differently instead of with the normal imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Imports\n",
    "import pipeline\n",
    "from pipeline import *\n",
    "from pipeline import Pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ME WHEN NOT USING DARK MODE\n",
    "import matplotlib as mpl\n",
    "COLOR = \"white\"\n",
    "#COLOR = \"black\"\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR\n",
    "\n",
    "## A4 paper\n",
    "mpl.rcParams['figure.figsize'] = [11.3, 8.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    raw_image_dir = os.path.expanduser(\"~/mnt/jgt/2022/0301\"),\n",
    "    image_prefix = \"l138_0\",\n",
    "    bias_prefix = \"bias\",\n",
    "    n_sets = 9,\n",
    "    fits_extension = \".fits\",\n",
    "    fits_date_format = \"%Y.%m.%dT%H:%M:%S.%f\",\n",
    "    has_filter_in_header = False,\n",
    "    n_sample_periods = 100,\n",
    "    amplitude_score_threshold = 0.85,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataAnalyser, un-adjusted\n",
    "da = DataAnalyser(config, adjusted=False)\n",
    "\n",
    "mean, std, med, n_positive = da.get_means_and_stds()\n",
    "source_ids = da.get_source_ids()\n",
    "da.plot_means_and_stds()\n",
    "    \n",
    "vd = VariableDetector(config, source_ids, mean, std, med, n_positive, adjusted=False)\n",
    "exclude_ids = vd.std_dev_search(config.avg_exclude_threshold, adjusted=False)\n",
    "avg_ids = da.get_ids_for_avg(exclude_ids)\n",
    "\n",
    "da.make_avg_curve(avg_ids)\n",
    "ff.plot_avg_light_curve(config.avg_curve_path, show=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pipeline.run_existing(config, assume_already_adjusted=True, show_plots=True, show_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = Config(\n",
    "        raw_image_dir = os.path.expanduser(\"~/mnt/data/tmp/napier3/Variable\"),\n",
    "        image_dir = os.path.expanduser(\"~/mnt/data/tmp/napier3/Variable\"),\n",
    "        image_prefix = \"Variable\",\n",
    "        has_filter_in_header = False,\n",
    "        n_sets = 1,\n",
    "        set_size = 169,\n",
    "        image_width = 1663,\n",
    "        image_height = 1252,\n",
    "    )\n",
    "    c = Cataloguer(config)\n",
    "\n",
    "    catalogue_set_number = 1\n",
    "    catalogue_image_number = 1\n",
    "\n",
    "    catalogue_image_path = os.path.join(config.image_dir,\n",
    "            config.image_format_str\n",
    "            .format(catalogue_set_number, catalogue_image_number))\n",
    "\n",
    "    n_sources = c.generate_catalogue(catalogue_image_path, solve=False, write_file=False)\n",
    "    \n",
    "    ff = FluxFinder(config, n_sources)\n",
    "    \n",
    "    ff.plot_given_light_curves([108], show=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "from pipeline import *\n",
    "\n",
    "config = Config(\n",
    "    #raw_image_dir = os.path.expanduser(\"~/mnt/jgt/2022/0301\"),\n",
    "    image_prefix = \"l198\",\n",
    "    n_sets = 9,\n",
    ")\n",
    "\n",
    "file = os.path.expanduser(\"~/mnt/data/tmp/jgt_images/r_l198_1_001.fit\")\n",
    "out_file = os.path.expanduser(\"./test.fit\")\n",
    "\n",
    "c = Cataloguer(config)\n",
    "\n",
    "_, wcs_header = c.get_wcs_header(file)\n",
    "data = fits.getdata(file, ignore_missing_end=True)\n",
    "head = fits.getheader(file, ignore_missing_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.ImageHDU(data, head)\n",
    "hdu2 = fits.PrimaryHDU(header=wcs_header)\n",
    "hdu.scale(\"uint16\")\n",
    "hdul = fits.HDUList([hdu2, hdu], None)\n",
    "hdul.writeto(out_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_header = fits.Header()\n",
    "\n",
    "for item in head.items():\n",
    "    new_header.append(item, end=True)\n",
    "\n",
    "for item in wcs_header.items():\n",
    "    if item[0] == \"bscale\" or item[0] == \"bzero\":\n",
    "        continue\n",
    "    new_header.append(item, end=True)\n",
    "    \n",
    "new_hdu = fits.PrimaryHDU(data=data, header=new_header)\n",
    "new_hdu.scale(\"uint16\")\n",
    "hdul = fits.HDUList([new_hdu], None)\n",
    "hdul.writeto(out_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "661cda2bc47445e7c6e25a640ed59596e312375c87e120a1d4c7c6ced0f09253"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
